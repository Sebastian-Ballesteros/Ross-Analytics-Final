---
title: "FINAL PROJECT"
author: "Sebasti√°n Ballesteros"
date: "2023-03-20"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: lumen
    highlight: z
---
# Project Guidelines
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# loading libraries
```{r}
library(class)
library(caret)
library(ggplot2)
library(gmodels)
library(neuralnet)
library(glmnet)
library(stringr)
library(kernlab)
library(C50)
```

# Data Cleaning
```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL
```

## Getting Data Ready for Analysis
```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```

## Getting Train and Test Samples
```{r}
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), nrow(tele_norm)/2) 

tele_train <- tele_norm[-test_set,]
tele_test  <- tele_norm[test_set,]
```

# Logit Model

## Backwards Regression
```{r eval=FALSE}
logit_model<- step(glm(yyes ~ . ,data=tele_train, family = "binomial"), 
                   direction = c("backward"))

saveRDS(logit_model,"logit_model")
```

### Summary Logit

```{r}
logit_model <- readRDS("logit_model")

summary(logit_model)
```
### Logit Model Results

An activation threshold of 0.15 will be used from now on as it has proven to maximize profits and maximize kappa from other homeworks and assignmets done on this dataset
```{r}
logit_pred<-predict(logit_model, newdata = tele_test , type = "response")

pred<-as.factor(ifelse(logit_pred>=0.15,1,0))
test<-as.factor(tele_test$yyes)

confusionMatrix(pred,test, positive = "1")
```


# Support Vector Machines

## Training an SVM with every kernel
```{r eval = FALSE}
kernels <- c("rbfdot", "polydot", "tanhdot", "vanilladot", "laplacedot", "besseldot", "anovadot", "splinedot")
svms <- c()

for (i in kernels){
  svm_model <- ksvm(as.factor(yyes) ~ ., data = tele_train, kernel = i)
  svms <- append(svms,svm_model)
}

names(svms) <- kernels

saveRDS(svms,"svms")
```
## Predicting with SVM's

```{r eval=FALSE}
SVMs <- readRDS("svms")

SVM_df <- data.frame(rbfdot = predict(SVMs$rbfdot,tele_test))

SVM_df$polydot    <- predict(SVMs$polydot,tele_test)
SVM_df$tanhdot    <- predict(SVMs$tanhdot,tele_test)
SVM_df$vanilladot <- predict(SVMs$vanilladot,tele_test)
SVM_df$laplacedot <- predict(SVMs$laplacedot,tele_test)
SVM_df$besseldot  <- predict(SVMs$besseldot,tele_test)
SVM_df$anovadot   <- predict(SVMs$anovadot,tele_test)
SVM_df$splinedot  <- predict(SVMs$splinedot,tele_test)

saveRDS(SVM_df, "svm_pred")
```

## SVM's performance

```{r}
svms     <- readRDS("svms")
svm_pred <- readRDS("svm_pred")
```

### rbfdot
```{r}
confusionMatrix(as.factor(svm_pred$rbfdot), as.factor(tele_test$yyes))
```

### polydot
```{r}
confusionMatrix(as.factor(svm_pred$polydot), as.factor(tele_test$yyes))
```

### tanhdot
```{r}
confusionMatrix(as.factor(svm_pred$tanhdot), as.factor(tele_test$yyes))
```

### vanilladot
```{r}
confusionMatrix(as.factor(svm_pred$vanilladot), as.factor(tele_test$yyes))
```

### laplacedot
```{r}
confusionMatrix(as.factor(svm_pred$laplacedot), as.factor(tele_test$yyes))
```

### besseldot
```{r}
confusionMatrix(as.factor(svm_pred$besseldot), as.factor(tele_test$yyes))
```

### anovadot
```{r}
confusionMatrix(as.factor(svm_pred$anovadot), as.factor(tele_test$yyes))
```

### splinedot
```{r}
confusionMatrix(as.factor(svm_pred$splinedot), as.factor(tele_test$yyes))
```


# Decision Tree

The first model built is the Decision Tree. The C5.0 function from the C50 library is used to build the model. The formula used in this case is as.factor(yyes) ~ . which means that the model will use all the other columns to predict the "yyes" column, which is the outcome of interest.

## DT
```{r}
DT_model <- C5.0(as.factor(yyes) ~ ., data = tele_train)
```

### Decision Tree results
```{r}
DT_pred <- as.numeric(predict(DT_model, tele_test))-1

confusionMatrix(as.factor(DT_pred),as.factor(tele_test$yyes), positive = "1")
```

# DT Cost Matrix 
```{r}
#Given the original prompt for the project, and the fact that the tune function for tuning does not run on my computer, i have decided to only see if implementing the 6$ revenue if a client purchases and a $1 cost for each call, meaning that if we call and they pick up we get a profit 5, and if we call them and we don't 
cost_matrix <- matrix(c(0,-1,0,5),ncol = 2)

DT_errorcost <- C5.0(as.factor(yyes) ~ ., data = tele_train, costs = cost_matrix)
```
## Cost Matrix DT results
```{r}
errorcost_pred <- predict(DT_errorcost, tele_test)

confusionMatrix(as.factor(errorcost_pred), as.factor(tele_test$yyes))
```

# Final Prediction
```{r}
combined_pred <- ifelse((ifelse(logit_pred>0.15,1,0) * DT_pred * as.numeric(svm_pred$vanilladot)-1) == 1, 1, 0)
confusionMatrix(as.factor(combined_pred),as.factor(tele_test$yyes))
```

# 10 Person List

## Selecting 10 people
```{r}
set.seed(12345)
today_list <- tele_norm[sample(1:nrow(tele_norm),10),]
today_list$yyes
```

## Ensamble prediction
```{r}
pred_today_logit <- ifelse(predict(logit_model, today_list, type = "response")>0.15,1,0)
pred_today_svm   <- predict(svms$vanilladot, today_list)
pred_today_DT    <- predict(DT_model, today_list)
```

### Who to call

call people with position n in the list as indicated below
```{r}
c(1:10)[(pred_today_logit * (as.numeric(pred_today_DT)-1) * (as.numeric(pred_today_svm)-1)) == 1]
```
In this case we dont call any of the 10 randomly sampled people

# Conclusion
 
After running all three level one models, It was evident that the best performing one was for the SVM was the Anovadot kernel, but due to the small number of observations, and debugging problems with prediction I opted to run Vanilladot for the 10 person list due to time constraints. Backwards Step-wise regression converged at 23 variables, and the Decision tree was better off without the cost matrix, as kappa did not change from one model to the other. 
